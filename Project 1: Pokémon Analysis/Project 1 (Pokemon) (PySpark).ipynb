{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11198568,"sourceType":"datasetVersion","datasetId":6991788}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Analysis (Using the Pyspark Library)","metadata":{}},{"cell_type":"markdown","source":"# Prefactory Remarks","metadata":{}},{"cell_type":"markdown","source":"- [x] **Necessary packages to use:**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, avg, when\nfrom pyspark.sql.types import IntegerType, StringType, BooleanType\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer, PCA\nfrom pyspark.ml.classification import (DecisionTreeClassifier,RandomForestClassifier,\n    MultilayerPerceptronClassifier,GBTClassifier)\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.tuning import TrainValidationSplit, CrossValidator, ParamGridBuilder\nfrom pyspark.sql import functions as F\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:48:35.952487Z","iopub.execute_input":"2025-03-29T23:48:35.952835Z","iopub.status.idle":"2025-03-29T23:48:38.852668Z","shell.execute_reply.started":"2025-03-29T23:48:35.952797Z","shell.execute_reply":"2025-03-29T23:48:38.851506Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## 1. Visualize the Data","metadata":{}},{"cell_type":"markdown","source":"- [x] **Start the PySpark session and view the data**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *  # For common SQL functions\nfrom pyspark.sql.types import *  # For defining custom schema types\n\nspark = SparkSession.builder.appName(\"Test_pokemon\").getOrCreate()\n\n\ndf = spark.read.csv(\"/kaggle/input/pokmon-dataset/pokemon_data.csv\", header=True, inferSchema=True)\n\ndf.show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T00:02:53.380894Z","iopub.execute_input":"2025-03-30T00:02:53.381262Z","iopub.status.idle":"2025-03-30T00:02:53.610155Z","shell.execute_reply.started":"2025-03-30T00:02:53.381237Z","shell.execute_reply":"2025-03-30T00:02:53.608966Z"}},"outputs":[{"name":"stdout","text":"+---+--------------------+------+------+---+------+-------+-------+-------+-----+----------+---------+\n|  #|                Name|Type 1|Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|\n+---+--------------------+------+------+---+------+-------+-------+-------+-----+----------+---------+\n|  1|           Bulbasaur| Grass|Poison| 45|    49|     49|     65|     65|   45|         1|    false|\n|  2|             Ivysaur| Grass|Poison| 60|    62|     63|     80|     80|   60|         1|    false|\n|  3|            Venusaur| Grass|Poison| 80|    82|     83|    100|    100|   80|         1|    false|\n|  3|VenusaurMega Venu...| Grass|Poison| 80|   100|    123|    122|    120|   80|         1|    false|\n|  4|          Charmander|  Fire|  NULL| 39|    52|     43|     60|     50|   65|         1|    false|\n+---+--------------------+------+------+---+------+-------+-------+-------+-----+----------+---------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"- [x] **Select only the name, HP stat, and Generation of Pokémon with Attack stat higher than 90**","metadata":{}},{"cell_type":"code","source":"df_selected = df.select(\"Name\",\"HP\",\"Generation\").filter(df[\"Attack\"]>90)\n\ndf_selected.show(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:48:54.928443Z","iopub.execute_input":"2025-03-29T23:48:54.928871Z","iopub.status.idle":"2025-03-29T23:48:55.302102Z","shell.execute_reply.started":"2025-03-29T23:48:54.928825Z","shell.execute_reply":"2025-03-29T23:48:55.301432Z"}},"outputs":[{"name":"stdout","text":"+--------------------+---+----------+\n|                Name| HP|Generation|\n+--------------------+---+----------+\n|VenusaurMega Venu...| 80|         1|\n|CharizardMega Cha...| 78|         1|\n|CharizardMega Cha...| 78|         1|\n|BlastoiseMega Bla...| 79|         1|\n|BeedrillMega Beed...| 65|         1|\n|           Sandslash| 75|         1|\n|           Nidoqueen| 90|         1|\n|            Nidoking| 81|         1|\n|            Parasect| 60|         1|\n|            Primeape| 65|         1|\n+--------------------+---+----------+\nonly showing top 10 rows\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 2. Clean the Data","metadata":{}},{"cell_type":"markdown","source":"- [x] **Check for any Null, NaN, or missing values \" \" in the stats columns. Fill all of the NaN values in the dataset with averages of the respective columns.**","metadata":{}},{"cell_type":"code","source":"null_count_HP = df.filter(df[\"HP\"].isNull() | (df[\"HP\"] == 0) | F.isnan(df[\"HP\"])).count()\nnull_count_Attack = df.filter(df[\"Attack\"].isNull() | (df[\"Attack\"] == 0) | F.isnan(df[\"Attack\"])).count()\nnull_count_Defense = df.filter(df[\"Defense\"].isNull() | (df[\"Defense\"] == 0) | F.isnan(df[\"Defense\"])).count()\nnull_count_Sp_Atk = df.filter(df[\"`Sp. Atk`\"].isNull() | (df[\"`Sp. Atk`\"] == 0) | F.isnan(df[\"`Sp. Atk`\"])).count()\nnull_count_Sp_Def = df.filter(df[\"`Sp. Def`\"].isNull() | (df[\"`Sp. Def`\"] == 0) | F.isnan(df[\"`Sp. Def`\"])).count()\nnull_count_Speed = df.filter(df[\"Speed\"].isNull() | (df[\"Speed\"] == 0) | F.isnan(df[\"Speed\"])).count()\n\nprint(null_count_HP)\nprint(null_count_Attack)\nprint(null_count_Defense)\nprint(null_count_Sp_Atk)\nprint(null_count_Sp_Def)\nprint(null_count_Speed)\n\n# No null, \" \", or NaN values to be found","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:48:55.302670Z","iopub.execute_input":"2025-03-29T23:48:55.302920Z","iopub.status.idle":"2025-03-29T23:48:57.435673Z","shell.execute_reply.started":"2025-03-29T23:48:55.302900Z","shell.execute_reply":"2025-03-29T23:48:57.434635Z"}},"outputs":[{"name":"stdout","text":"0\n0\n0\n0\n0\n0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"- [x] **By now you should've noticed that some names are wrong. Fix these: Mega, Forme, Mode, Wormadam, Rotom, Hoopa, Primal, and Kyurem.**","metadata":{}},{"cell_type":"code","source":"# We have names such as: Mega, Forme, Mode, Wormadam, Rotom, Hoopa, Primal, and Kyurem\n\n# Clean the mega names\n\nfrom pyspark.sql.functions import col, regexp_extract, regexp_replace\n\ndf = spark.read.csv(\"/kaggle/input/pokmon-dataset/pokemon_data.csv\", header=True, inferSchema=True)\n\n\ndf = df.withColumn(\"Name\", when(col(\"Name\").contains(\"Mega\"), regexp_extract(col(\"Name\"), r\"(Mega [A-Za-z]+.*)\", 0))\n    .otherwise(col(\"Name\"))  # If it doesn't contain \"Mega\", keep the original name\n)\n\n\n# Clean the Formes\n\n\ndf = df.withColumn(\"Name\", regexp_replace(col(\"Name\"), r\"(.+?)([A-Z][a-z]+) Forme\", r\"$1 ($2 Form)\"))\n\n\n# Clean the Modes\n\ndf = df.withColumn(\"Name\", regexp_replace(col(\"Name\"), r\"(.+?)([A-Z][a-z]+) Mode\", r\"$1 ($2 Mode)\"))\n\n\n# Clean the Wormadam (or cloaks)\n\n\ndf = df.withColumn(\"Name\", regexp_replace(col(\"Name\"), r\"(.+?)([A-Z][a-z]+) Cloak\", r\"$1 ($2 Cloak)\"))\n\n# Clean the Rotoms\n\ndf = df.withColumn(\"Name\", regexp_replace(col(\"Name\"), r\"Rotom([A-Z][a-z]+) Rotom\", r\"$1 Rotom\"))\n\n# Clean the Hoopas\n\ndf = df.withColumn(\"Name\", regexp_replace(col(\"Name\"), r\"Hoopa\\s*Hoopa\", \"Hoopa\"))\n\n# Clean the Primals\n\ndf = df.withColumn(\"Name\",regexp_replace(col(\"Name\"), r\"(\\w+)Primal (\\w+)\", r\"Primal $1\"))\n\n# Clean the Kyurem fusions\n\ndf = df.withColumn(\"Name\",regexp_replace(col(\"Name\"), r\"(\\w+)(Black|White) (\\w+)\", r\"$2 $1\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T00:05:57.580089Z","iopub.execute_input":"2025-03-30T00:05:57.580449Z","iopub.status.idle":"2025-03-30T00:05:57.818963Z","shell.execute_reply.started":"2025-03-30T00:05:57.580417Z","shell.execute_reply":"2025-03-30T00:05:57.817903Z"}},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":"- [x] **Check that it worked.**","metadata":{}},{"cell_type":"code","source":"df_deoxys = df.filter(col(\"Name\").rlike(\"Kyurem\"))\ndf_deoxys.show(truncate=False)\n\n# It did work","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T00:06:18.793375Z","iopub.execute_input":"2025-03-30T00:06:18.793698Z","iopub.status.idle":"2025-03-30T00:06:18.897149Z","shell.execute_reply.started":"2025-03-30T00:06:18.793675Z","shell.execute_reply":"2025-03-30T00:06:18.896124Z"}},"outputs":[{"name":"stdout","text":"+---+------------+------+------+---+------+-------+-------+-------+-----+----------+---------+\n|#  |Name        |Type 1|Type 2|HP |Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|\n+---+------------+------+------+---+------+-------+-------+-------+-----+----------+---------+\n|646|Kyurem      |Dragon|Ice   |125|130   |90     |130    |90     |95   |5         |true     |\n|646|Black Kyurem|Dragon|Ice   |125|170   |100    |120    |90     |95   |5         |true     |\n|646|White Kyurem|Dragon|Ice   |125|120   |90     |170    |100    |95   |5         |true     |\n+---+------------+------+------+---+------+-------+-------+-------+-----+----------+---------+\n\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"- [x] **Save the new clean csv file**","metadata":{}},{"cell_type":"code","source":"output_path = \"/kaggle/working/cleaned_pokemon_data.csv\"\ndf.write.option(\"header\", \"true\").csv(output_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T00:10:37.344532Z","iopub.execute_input":"2025-03-30T00:10:37.344993Z","iopub.status.idle":"2025-03-30T00:10:37.866142Z","shell.execute_reply.started":"2025-03-30T00:10:37.344959Z","shell.execute_reply":"2025-03-30T00:10:37.864625Z"}},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":"- [x] **Check if it saved (you should be able to see it to your right, in the Output section, above the table of contents)**","metadata":{}},{"cell_type":"code","source":"df = spark.read.csv(\"/kaggle/working/cleaned_pokemon_data.csv/part-00000-a867e6ce-b154-452b-92e8-cb41dc14fefb-c000.csv\", header=True, inferSchema=True)\n\ndf.show(5)\n\n# Yes, it did","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T00:12:22.057776Z","iopub.execute_input":"2025-03-30T00:12:22.058240Z","iopub.status.idle":"2025-03-30T00:12:22.296780Z","shell.execute_reply.started":"2025-03-30T00:12:22.058201Z","shell.execute_reply":"2025-03-30T00:12:22.295675Z"}},"outputs":[{"name":"stdout","text":"+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+\n|  #|         Name|Type 1|Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+\n|  1|    Bulbasaur| Grass|Poison| 45|    49|     49|     65|     65|   45|         1|    false|\n|  2|      Ivysaur| Grass|Poison| 60|    62|     63|     80|     80|   60|         1|    false|\n|  3|     Venusaur| Grass|Poison| 80|    82|     83|    100|    100|   80|         1|    false|\n|  3|Mega Venusaur| Grass|Poison| 80|   100|    123|    122|    120|   80|         1|    false|\n|  4|   Charmander|  Fire|  NULL| 39|    52|     43|     60|     50|   65|         1|    false|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":55},{"cell_type":"markdown","source":"## 3. Team Selection and Optimization","metadata":{}},{"cell_type":"markdown","source":"- [x] **Create the BST column and the Gigantamax BST column (BST doubled)**","metadata":{}},{"cell_type":"code","source":"# This here shows us that we must be careful with spaces and special characters like:\n# spaces(\" \"),parenthesis(\"( )\"),periods(\".\"),commas,semicolons,quotes/unquotes,hífens,$,!\n# The best thing to do is name the columns with underscores only, such as \"Sp. Atk\" -> \"Sp_Atk\"\n\ndf_BST = df.withColumn(\"BST\",col(\"HP\") +col(\"Attack\") +col(\"Defense\") +col(\"`Sp. Atk`\") + col(\"`Sp. Def`\") +col(\"Speed\"))   # Backticks for special characters (there can't be spacescol(\"`Sp. Def`\") +col(\"Speed\"))\n\ndf_BST = df_BST.withColumn(\"Giga BST\", col(\"BST\") * 2)\n\ndf_BST.show(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T00:15:43.164341Z","iopub.execute_input":"2025-03-30T00:15:43.164824Z","iopub.status.idle":"2025-03-30T00:15:43.302127Z","shell.execute_reply.started":"2025-03-30T00:15:43.164789Z","shell.execute_reply":"2025-03-30T00:15:43.300899Z"}},"outputs":[{"name":"stdout","text":"+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+--------+\n|  #|         Name|Type 1|Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|BST|Giga BST|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+--------+\n|  1|    Bulbasaur| Grass|Poison| 45|    49|     49|     65|     65|   45|         1|    false|318|     636|\n|  2|      Ivysaur| Grass|Poison| 60|    62|     63|     80|     80|   60|         1|    false|405|     810|\n|  3|     Venusaur| Grass|Poison| 80|    82|     83|    100|    100|   80|         1|    false|525|    1050|\n|  3|Mega Venusaur| Grass|Poison| 80|   100|    123|    122|    120|   80|         1|    false|625|    1250|\n|  4|   Charmander|  Fire|  NULL| 39|    52|     43|     60|     50|   65|         1|    false|309|     618|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+--------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"- [x] **Create a dataframe that only has the Pokémon that can Mega Evolve and their respective Mega evolutions.**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import col, regexp_extract\n\n# Get only the Megas (ordered by BST in descending order)\n\nmega_pokemon_df = df_BST.filter(col(\"Name\").rlike(\"Mega\") & (col(\"Legendary\") == False)) \n\n\n# Create the base names in another dataframe, we only need this to extract the base names, it looks ugly\n\nmega_pokemon_df_BN = mega_pokemon_df.withColumn(\"Base_Name\",\n    F.when(col(\"Name\").rlike(\"Mega\"), \n        F.regexp_replace(col(\"Name\"), r\"^Mega\\s|\\s(X|Y)\\s?|\\s+$\", \"\")\n    ).otherwise(col(\"Name\")))\n\n\n# Get a list with all of the base names\n\nbase_names_list = mega_pokemon_df_BN.select(\"Base_Name\").rdd.flatMap(lambda x: x).collect()\n\n# Let's remove duplicates from the base_names_list\n\nlist_2 = []\nfor i in base_names_list:\n    if i not in list_2:\n        list_2.append(i)\n\n# print(list_2)\n\nmega_candidates = df_BST.filter((col(\"Name\").isin(list_2)))\n\n\nfinal_df = mega_pokemon_df.union(mega_candidates)\n\nfinal_df.orderBy(col(\"BST\"), ascending=True).show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T01:21:58.027566Z","iopub.execute_input":"2025-03-30T01:21:58.027944Z","iopub.status.idle":"2025-03-30T01:21:58.534976Z","shell.execute_reply.started":"2025-03-30T01:21:58.027913Z","shell.execute_reply":"2025-03-30T01:21:58.533952Z"}},"outputs":[{"name":"stdout","text":"+---+-------------+--------+-------+---+------+-------+-------+-------+-----+----------+---------+---+--------+\n|  #|         Name|  Type 1| Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|BST|Giga BST|\n+---+-------------+--------+-------+---+------+-------+-------+-------+-----+----------+---------+---+--------+\n|302|      Sableye|    Dark|  Ghost| 50|    75|     75|     65|     65|   50|         3|    false|380|     760|\n|303|       Mawile|   Steel|  Fairy| 50|    85|     85|     55|     55|   50|         3|    false|380|     760|\n| 15|     Beedrill|     Bug| Poison| 65|    90|     40|     45|     80|   75|         1|    false|395|     790|\n|308|     Medicham|Fighting|Psychic| 60|    60|     75|     60|     75|   80|         3|    false|410|     820|\n|531|       Audino|  Normal|   NULL|103|    60|     86|     60|     86|   50|         5|    false|445|     890|\n|354|      Banette|   Ghost|   NULL| 64|   115|     65|     83|     63|   65|         3|    false|455|     910|\n|319|     Sharpedo|   Water|   Dark| 70|   120|     40|     95|     40|   95|         3|    false|460|     920|\n|323|     Camerupt|    Fire| Ground| 70|   100|     70|    105|     75|   40|         3|    false|460|     920|\n|359|        Absol|    Dark|   NULL| 65|   130|     60|     75|     60|   75|         3|    false|465|     930|\n|310|    Manectric|Electric|   NULL| 70|    75|     60|    105|     60|  105|         3|    false|475|     950|\n| 18|      Pidgeot|  Normal| Flying| 83|    80|     75|     70|     70|  101|         1|    false|479|     958|\n|302| Mega Sableye|    Dark|  Ghost| 50|    85|    125|     85|    115|   20|         3|    false|480|     960|\n|362|       Glalie|     Ice|   NULL| 80|    80|     80|     80|     80|   80|         3|    false|480|     960|\n|303|  Mega Mawile|   Steel|  Fairy| 50|   105|    125|     55|     95|   50|         3|    false|480|     960|\n|428|      Lopunny|  Normal|   NULL| 65|    76|     84|     54|     96|  105|         4|    false|480|     960|\n| 80|      Slowbro|   Water|Psychic| 95|    75|    110|    100|     80|   30|         1|    false|490|     980|\n|115|   Kangaskhan|  Normal|   NULL|105|    95|     80|     40|     80|   90|         1|    false|490|     980|\n|334|      Altaria|  Dragon| Flying| 75|    70|     90|     70|    105|   80|         3|    false|490|     980|\n|460|    Abomasnow|   Grass|    Ice| 90|    92|     75|     92|     85|   60|         4|    false|494|     988|\n| 15|Mega Beedrill|     Bug| Poison| 65|   150|     40|     15|     80|  145|         1|    false|495|     990|\n+---+-------------+--------+-------+---+------+-------+-------+-------+-----+----------+---------+---+--------+\nonly showing top 20 rows\n\n","output_type":"stream"}],"execution_count":105},{"cell_type":"markdown","source":"- [x] **Find the best Fire-type team (Only 6 Pokémon, no duplicate species, only one Mega evolution)**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import col, regexp_extract\n\n# Get only the Megas (ordered by BST in descending order)\n\nmega_pokemon_df = df_BST.filter(col(\"Name\").rlike(\"Mega\") & (col(\"Legendary\") == False)) \\\n                        .orderBy(col(\"BST\"), ascending=False)\n\nmega_pokemon_df = mega_pokemon_df.withColumn(\"Base_Name\",\n    F.when(col(\"Name\").rlike(\"Mega\"), \n        F.regexp_replace(col(\"Name\"), r\"^Mega\\s|\\s(X|Y)\\s?|\\s+$\", \"\")\n    ).otherwise(col(\"Name\")))\n\n# Now, filter them by type, and pick the first instance\n\nmega_pokemon_fdf = mega_pokemon_df.filter((col(\"`Type 1`\") == \"Fire\") | (col(\"`Type 2`\") == \"Fire\")).limit(1)\n\n# Now get the name of the Pokémon so that we can exclude it from the other list of 5\n\nbase_name_row = mega_pokemon_fdf.select(\"Base_Name\").first()\nbase_name = base_name_row[\"Base_Name\"]             # This returns Charizard for the Fire types\n\nnon_mega_fdf = df_BST.filter((~col(\"Name\").rlike(\"Mega\")) & (~col(\"Name\").rlike(base_name)) \n                             & ((col(\"`Type 1`\") == \"Fire\") | (col(\"`Type 2`\") == \"Fire\")) \n                             & (col(\"Legendary\") == False)) \\\n                     .orderBy(col(\"BST\"), ascending=False).limit(5)\n\n# Now, join these two (in order to do that, we must add a Base_name column to non_mega_df as well)\n\nnon_mega_fdf = non_mega_fdf.withColumn(\"Base_Name\", lit(None))\nfinal_team_df = mega_pokemon_fdf.union(non_mega_fdf).orderBy(col(\"BST\"), ascending=False)\n\n\nfinal_team_df.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T00:49:17.862443Z","iopub.execute_input":"2025-03-30T00:49:17.862826Z","iopub.status.idle":"2025-03-30T00:49:18.462383Z","shell.execute_reply.started":"2025-03-30T00:49:17.862797Z","shell.execute_reply":"2025-03-30T00:49:18.461389Z"}},"outputs":[{"name":"stdout","text":"+---+--------------------+------+--------+---+------+-------+-------+-------+-----+----------+---------+---+--------+---------+\n|  #|                Name|Type 1|  Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|BST|Giga BST|Base_Name|\n+---+--------------------+------+--------+---+------+-------+-------+-------+-----+----------+---------+---+--------+---------+\n|  6|    Mega Charizard X|  Fire|  Dragon| 78|   130|    111|    130|     85|  100|         1|    false|634|    1268|Charizard|\n| 59|            Arcanine|  Fire|    NULL| 90|   110|     80|    100|     80|   95|         1|    false|555|    1110|     NULL|\n|637|           Volcarona|   Bug|    Fire| 85|    60|     65|    135|    105|  100|         5|    false|550|    1100|     NULL|\n|467|           Magmortar|  Fire|    NULL| 75|    95|     67|    125|     95|   83|         4|    false|540|    1080|     NULL|\n|555|Darmanitan (Zen M...|  Fire| Psychic|105|    30|    105|    140|    105|   55|         5|    false|540|    1080|     NULL|\n|392|           Infernape|  Fire|Fighting| 76|   104|     71|    104|     71|  108|         4|    false|534|    1068|     NULL|\n+---+--------------------+------+--------+---+------+-------+-------+-------+-----+----------+---------+---+--------+---------+\n\n","output_type":"stream"}],"execution_count":81},{"cell_type":"markdown","source":"## 4. Visualizations","metadata":{}},{"cell_type":"markdown","source":"- [x] **All of the representations for this dataset have already been done in the Pandas notebook, so I'll refrain from repeating them, seing that we would use matplotlib for such.**","metadata":{}},{"cell_type":"markdown","source":"## 5. String Manipulations","metadata":{}},{"cell_type":"markdown","source":"- [x] **Select all of the Pokémon whose names start with a 'Pi' and are Flying type**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import col\n\nfiltered_df = df.filter((col(\"Name\").startswith(\"Pi\")) & \n                        ((col(\"Type 1\") == \"Flying\") | (col(\"Type 2\") == \"Flying\")))\nfiltered_df.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:00.823223Z","iopub.execute_input":"2025-03-29T23:49:00.823558Z","iopub.status.idle":"2025-03-29T23:49:01.153957Z","shell.execute_reply.started":"2025-03-29T23:49:00.823526Z","shell.execute_reply":"2025-03-29T23:49:01.152503Z"}},"outputs":[{"name":"stdout","text":"+---+---------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+\n|  #|     Name|Type 1|Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|BST|\n+---+---------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+\n| 16|   Pidgey|Normal|Flying| 40|    45|     40|     35|     35|   56|         1|    false|251|\n| 17|Pidgeotto|Normal|Flying| 63|    60|     55|     50|     50|   71|         1|    false|349|\n| 18|  Pidgeot|Normal|Flying| 83|    80|     75|     70|     70|  101|         1|    false|479|\n|519|   Pidove|Normal|Flying| 50|    55|     50|     36|     30|   43|         5|    false|264|\n+---+---------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"- [x] **Check if any names contain any digits**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import col\n\nfiltered_df = df.filter(col(\"Name\").rlike(\"[0-9]\"))\nfiltered_df.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:01.154783Z","iopub.execute_input":"2025-03-29T23:49:01.157845Z","iopub.status.idle":"2025-03-29T23:49:01.489623Z","shell.execute_reply.started":"2025-03-29T23:49:01.157806Z","shell.execute_reply":"2025-03-29T23:49:01.488842Z"}},"outputs":[{"name":"stdout","text":"+---+----------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+\n|  #|            Name|Type 1|Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|BST|\n+---+----------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+\n|233|        Porygon2|Normal|  NULL| 85|    80|     90|    105|     95|   60|         2|    false|515|\n|718|Zygarde50% Forme|Dragon|Ground|108|   100|    121|     81|     95|   95|         6|     true|600|\n+---+----------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"- [x] **Replace all of the spaces with underscores in the name column**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import regexp_replace\n\ndf_with_underscores = df.withColumn(\"Name_Underscores\", regexp_replace(col(\"Name\"), \" \", \"_\"))\ndf_with_underscores.show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:01.490714Z","iopub.execute_input":"2025-03-29T23:49:01.491106Z","iopub.status.idle":"2025-03-29T23:49:01.781662Z","shell.execute_reply.started":"2025-03-29T23:49:01.491069Z","shell.execute_reply":"2025-03-29T23:49:01.780346Z"}},"outputs":[{"name":"stdout","text":"+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+----------------+\n|  #|         Name|Type 1|Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|BST|Name_Underscores|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+----------------+\n|  1|    Bulbasaur| Grass|Poison| 45|    49|     49|     65|     65|   45|         1|    false|318|       Bulbasaur|\n|  2|      Ivysaur| Grass|Poison| 60|    62|     63|     80|     80|   60|         1|    false|405|         Ivysaur|\n|  3|     Venusaur| Grass|Poison| 80|    82|     83|    100|    100|   80|         1|    false|525|        Venusaur|\n|  3|Mega Venusaur| Grass|Poison| 80|   100|    123|    122|    120|   80|         1|    false|625|   Mega_Venusaur|\n|  4|   Charmander|  Fire|  NULL| 39|    52|     43|     60|     50|   65|         1|    false|309|      Charmander|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+----------------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"- [x] **Concatenate the values of Type 1 and Type 2**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import concat_ws\n\ndf_with_types = df.withColumn(\"Combined_Types\", concat_ws(\", \", col(\"Type 1\"), col(\"Type 2\")))\ndf_with_types.show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:01.782461Z","iopub.execute_input":"2025-03-29T23:49:01.782815Z","iopub.status.idle":"2025-03-29T23:49:02.049018Z","shell.execute_reply.started":"2025-03-29T23:49:01.782782Z","shell.execute_reply":"2025-03-29T23:49:02.048054Z"}},"outputs":[{"name":"stdout","text":"+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+--------------+\n|  #|         Name|Type 1|Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|BST|Combined_Types|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+--------------+\n|  1|    Bulbasaur| Grass|Poison| 45|    49|     49|     65|     65|   45|         1|    false|318| Grass, Poison|\n|  2|      Ivysaur| Grass|Poison| 60|    62|     63|     80|     80|   60|         1|    false|405| Grass, Poison|\n|  3|     Venusaur| Grass|Poison| 80|    82|     83|    100|    100|   80|         1|    false|525| Grass, Poison|\n|  3|Mega Venusaur| Grass|Poison| 80|   100|    123|    122|    120|   80|         1|    false|625| Grass, Poison|\n|  4|   Charmander|  Fire|  NULL| 39|    52|     43|     60|     50|   65|         1|    false|309|          Fire|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+--------------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"- [x] **Split Pokémon names into individual letters and count the number of vowels**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import col, length, regexp_replace\n\ndf_with_vowels_count = df.withColumn(\"Vowels_Count\", \nlength(regexp_replace(col(\"Name\"), \"[^aeiouAEIOU]\", \"\"))  # Remove non-vowels and count the length\n)\ndf_with_vowels_count.show(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:02.049853Z","iopub.execute_input":"2025-03-29T23:49:02.050186Z","iopub.status.idle":"2025-03-29T23:49:02.377575Z","shell.execute_reply.started":"2025-03-29T23:49:02.050154Z","shell.execute_reply":"2025-03-29T23:49:02.376541Z"}},"outputs":[{"name":"stdout","text":"+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+------------+\n|  #|         Name|Type 1|Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|BST|Vowels_Count|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+------------+\n|  1|    Bulbasaur| Grass|Poison| 45|    49|     49|     65|     65|   45|         1|    false|318|           4|\n|  2|      Ivysaur| Grass|Poison| 60|    62|     63|     80|     80|   60|         1|    false|405|           3|\n|  3|     Venusaur| Grass|Poison| 80|    82|     83|    100|    100|   80|         1|    false|525|           4|\n|  3|Mega Venusaur| Grass|Poison| 80|   100|    123|    122|    120|   80|         1|    false|625|           6|\n|  4|   Charmander|  Fire|  NULL| 39|    52|     43|     60|     50|   65|         1|    false|309|           3|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+------------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"- [x] **Extract the first 3 letters of each Pokémon's name**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import col, substring\n\n\ndf_with_first_3_letters = df.withColumn(\"1st_3\", substring(col(\"Name\"), 1, 3))\ndf_with_first_3_letters.show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:02.378424Z","iopub.execute_input":"2025-03-29T23:49:02.378804Z","iopub.status.idle":"2025-03-29T23:49:02.618239Z","shell.execute_reply.started":"2025-03-29T23:49:02.378767Z","shell.execute_reply":"2025-03-29T23:49:02.616892Z"}},"outputs":[{"name":"stdout","text":"+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+-----+\n|  #|         Name|Type 1|Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|BST|1st_3|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+-----+\n|  1|    Bulbasaur| Grass|Poison| 45|    49|     49|     65|     65|   45|         1|    false|318|  Bul|\n|  2|      Ivysaur| Grass|Poison| 60|    62|     63|     80|     80|   60|         1|    false|405|  Ivy|\n|  3|     Venusaur| Grass|Poison| 80|    82|     83|    100|    100|   80|         1|    false|525|  Ven|\n|  3|Mega Venusaur| Grass|Poison| 80|   100|    123|    122|    120|   80|         1|    false|625|  Meg|\n|  4|   Charmander|  Fire|  NULL| 39|    52|     43|     60|     50|   65|         1|    false|309|  Cha|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+-----+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"- [x] **Convert the first two characters of name to uppercase and the rest to lowercase**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import col, upper, lower, substring\n\ndf_with_modified_name = df.withColumn(\"Modified_Name\", \nupper(substring(col(\"Name\"), 1, 2)) + lower(substring(col(\"Name\"), 3, 1000))\n)\n\ndf_with_modified_name.show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:02.619320Z","iopub.execute_input":"2025-03-29T23:49:02.619680Z","iopub.status.idle":"2025-03-29T23:49:03.002966Z","shell.execute_reply.started":"2025-03-29T23:49:02.619648Z","shell.execute_reply":"2025-03-29T23:49:03.001961Z"}},"outputs":[{"name":"stdout","text":"+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+-------------+\n|  #|         Name|Type 1|Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|BST|Modified_Name|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+-------------+\n|  1|    Bulbasaur| Grass|Poison| 45|    49|     49|     65|     65|   45|         1|    false|318|         NULL|\n|  2|      Ivysaur| Grass|Poison| 60|    62|     63|     80|     80|   60|         1|    false|405|         NULL|\n|  3|     Venusaur| Grass|Poison| 80|    82|     83|    100|    100|   80|         1|    false|525|         NULL|\n|  3|Mega Venusaur| Grass|Poison| 80|   100|    123|    122|    120|   80|         1|    false|625|         NULL|\n|  4|   Charmander|  Fire|  NULL| 39|    52|     43|     60|     50|   65|         1|    false|309|         NULL|\n+---+-------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+-------------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## 6. Further Analysis","metadata":{}},{"cell_type":"markdown","source":"- [x] **Find the most balanced Pokemon** (Balanced stats as in not much disparity between any two stats).  ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Science (Using the Pyspark Library)","metadata":{}},{"cell_type":"markdown","source":"## 7. Inferential Statistics","metadata":{}},{"cell_type":"markdown","source":"- [x] **Speed vs Defense tradeoff analysis**.  ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- [x] **Compute the average stats per type (Just use Type 1 here)**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql import functions as F\n\n\ndf_avg = df.groupBy(\"`Type 1`\").agg(\n    F.avg(\"HP\").alias(\"Average HP\"),\n    F.avg(\"Attack\").alias(\"Average Attack\"),\n    F.avg(\"Defense\").alias(\"Average Defense\"),\n    F.avg(\"`Sp. Atk`\").alias(\"Average Sp. Atk\"),  # Use backticks for special characters\n    F.avg(\"`Sp. Def`\").alias(\"Average Sp. Def\"),  # Use backticks for special characters\n    F.avg(\"Speed\").alias(\"Average Speed\")\n)\n\ndf_avg.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:03.004346Z","iopub.execute_input":"2025-03-29T23:49:03.004699Z","iopub.status.idle":"2025-03-29T23:49:03.954894Z","shell.execute_reply.started":"2025-03-29T23:49:03.004667Z","shell.execute_reply":"2025-03-29T23:49:03.950316Z"}},"outputs":[{"name":"stdout","text":"+--------+-----------------+------------------+------------------+------------------+------------------+------------------+\n|  Type 1|       Average HP|    Average Attack|   Average Defense|   Average Sp. Atk|   Average Sp. Def|     Average Speed|\n+--------+-----------------+------------------+------------------+------------------+------------------+------------------+\n|   Water|          72.0625| 74.15178571428571| 72.94642857142857|           74.8125| 70.51785714285714| 65.96428571428571|\n|  Poison|            67.25| 74.67857142857143| 68.82142857142857| 60.42857142857143| 64.39285714285714| 63.57142857142857|\n|   Steel|65.22222222222223| 92.70370370370371|126.37037037037037| 67.51851851851852| 80.62962962962963| 55.25925925925926|\n|    Rock|65.36363636363636| 92.86363636363636|100.79545454545455| 63.34090909090909| 75.47727272727273| 55.90909090909091|\n|     Ice|             72.0|             72.75| 71.41666666666667| 77.54166666666667| 76.29166666666667|63.458333333333336|\n|   Ghost|          64.4375|          73.78125|           81.1875|          79.34375|          76.46875|          64.34375|\n|   Fairy|74.11764705882354|61.529411764705884| 65.70588235294117| 78.52941176470588| 84.70588235294117|48.588235294117645|\n| Psychic|70.63157894736842| 71.45614035087719|  67.6842105263158| 98.40350877192982| 86.28070175438596| 81.49122807017544|\n|  Dragon|          83.3125|           112.125|            86.375|          96.84375|          88.84375|          83.03125|\n|  Flying|            70.75|             78.75|             66.25|             94.25|              72.5|             102.5|\n|     Bug|56.88405797101449| 70.97101449275362| 70.72463768115942|53.869565217391305| 64.79710144927536| 61.68115942028985|\n|Electric|59.79545454545455|  69.0909090909091| 66.29545454545455| 90.02272727272727| 73.70454545454545|              84.5|\n|    Fire|69.90384615384616| 84.76923076923077| 67.76923076923077| 88.98076923076923| 72.21153846153847|  74.4423076923077|\n|  Ground|         73.78125|             95.75|          84.84375|          56.46875|             62.75|          63.90625|\n|    Dark|66.80645161290323| 88.38709677419355|  70.2258064516129| 74.64516129032258| 69.51612903225806| 76.16129032258064|\n|Fighting|69.85185185185185| 96.77777777777777| 65.92592592592592|53.111111111111114| 64.70370370370371| 66.07407407407408|\n|   Grass|67.27142857142857| 73.21428571428571|              70.8|              77.5| 70.42857142857143| 61.92857142857143|\n|  Normal|77.27551020408163| 73.46938775510205|  59.8469387755102|55.816326530612244|63.724489795918366| 71.55102040816327|\n+--------+-----------------+------------------+------------------+------------------+------------------+------------------+\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"- [x] **Create the averages of the stats per type (Include both Type 1 and Type 2)**","metadata":{}},{"cell_type":"code","source":"from pyspark.sql import functions as F\n\n# Combine Type 1 and Type 2 into a single column (exploding the types)\ndf_combined = df.select(F.col(\"`Type 1`\").alias(\"Type\"), \"HP\", \"Attack\", \"Defense\", \"`Sp. Atk`\", \"`Sp. Def`\", \"Speed\") \\\n                .union(df.select(F.col(\"`Type 2`\").alias(\"Type\"), \"HP\", \"Attack\", \"Defense\", \"`Sp. Atk`\", \"`Sp. Def`\", \"Speed\"))\n\n# Now group by the Type column and compute the averages\ndf_g = df_combined.groupBy(\"Type\").agg(\n    F.avg(\"HP\").alias(\"Average HP\"),\n    F.avg(\"Attack\").alias(\"Average Attack\"),\n    F.avg(\"Defense\").alias(\"Average Defense\"),\n    F.avg(\"`Sp. Atk`\").alias(\"Average Sp. Atk\"),\n    F.avg(\"`Sp. Def`\").alias(\"Average Sp. Def\"),\n    F.avg(\"Speed\").alias(\"Average Speed\")\n)\n\ndf_g.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:03.964008Z","iopub.execute_input":"2025-03-29T23:49:03.965556Z","iopub.status.idle":"2025-03-29T23:49:04.662688Z","shell.execute_reply.started":"2025-03-29T23:49:03.965508Z","shell.execute_reply":"2025-03-29T23:49:04.661689Z"}},"outputs":[{"name":"stdout","text":"+--------+------------------+------------------+------------------+------------------+------------------+-----------------+\n|    Type|        Average HP|    Average Attack|   Average Defense|   Average Sp. Atk|   Average Sp. Def|    Average Speed|\n+--------+------------------+------------------+------------------+------------------+------------------+-----------------+\n|   Water| 71.02380952380952|  73.7063492063492|  74.2936507936508| 74.77777777777777| 70.30952380952381|64.98412698412699|\n|  Poison|62.596774193548384| 70.79032258064517| 63.74193548387097| 67.88709677419355| 67.41935483870968|65.25806451612904|\n|   Steel| 64.95918367346938| 92.65306122448979|116.61224489795919| 72.10204081632654| 83.16326530612245|57.10204081632653|\n|    Rock| 66.01724137931035| 90.72413793103448|107.08620689655173| 60.39655172413793|  73.8103448275862|51.10344827586207|\n|     Ice| 78.63157894736842| 82.05263157894737| 76.65789473684211| 83.10526315789474| 79.42105263157895|67.57894736842105|\n|   Ghost| 62.82608695652174| 76.93478260869566| 81.52173913043478| 77.47826086956522| 76.95652173913044|61.15217391304348|\n|   Fairy|            68.475|            61.575|              70.4|              76.5|            83.125|            55.85|\n| Psychic| 71.21111111111111| 72.64444444444445| 74.77777777777777|              94.6| 86.76666666666667|77.08888888888889|\n|  Dragon|              82.9|            105.76|             86.62|             97.44|              86.9|            82.14|\n|  Flying| 71.36633663366337| 80.22772277227723| 68.22772277227723| 76.36633663366337| 71.25742574257426|86.38613861386139|\n|     Bug|56.736111111111114| 71.76388888888889| 71.11111111111111| 53.56944444444444| 64.66666666666667|61.68055555555556|\n|Electric|              63.2|             69.52|             66.54|             88.96|             73.68|            82.94|\n|    Fire|          70.15625|         84.109375|          70.09375|              93.0|         74.328125|        75.421875|\n|  Ground| 75.58208955223881| 92.67164179104478| 87.70149253731343|61.208955223880594| 64.83582089552239|59.07462686567164|\n|    Dark| 70.23529411764706|  96.7843137254902| 70.94117647058823| 77.45098039215686|  69.6470588235294|75.84313725490196|\n|Fighting| 74.56603773584905|104.66037735849056| 74.05660377358491|  66.9245283018868| 73.37735849056604|76.52830188679245|\n|   Grass| 66.05263157894737| 73.46315789473684| 73.25263157894737| 72.93684210526315| 71.50526315789473|60.71578947368421|\n|  Normal| 76.73529411764706| 72.65686274509804|  59.6078431372549| 57.07843137254902|63.745098039215684|72.24509803921569|\n|    NULL| 67.76683937823834| 74.52590673575129| 67.58549222797927| 68.28497409326425| 67.97409326424871|65.87823834196891|\n+--------+------------------+------------------+------------------+------------------+------------------+-----------------+\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"- [x] **Compute the median Attack stat using only the Legendary Pokémon, and fill it in a new column called (Med_Atk) that has NULL for all Pokémon that aren't Legendary and this median for all that are.**","metadata":{}},{"cell_type":"code","source":"legendary_df = df.filter(df[\"Legendary\"] == True)\n\nmedian_attack = legendary_df.approxQuantile(\"Attack\", [0.5], 0.01)[0] # just return the 2nd value, which is the median, the others are the 25th and 75th percentiles\n\ndf_with_median = df.withColumn(\n    \"Med_Atk\",\n    F.when(df[\"Legendary\"] == True, F.lit(median_attack)).otherwise(F.lit(None))\n)\n\n\ndf_with_median.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:04.664280Z","iopub.execute_input":"2025-03-29T23:49:04.664576Z","iopub.status.idle":"2025-03-29T23:49:05.191993Z","shell.execute_reply.started":"2025-03-29T23:49:04.664552Z","shell.execute_reply":"2025-03-29T23:49:05.190873Z"}},"outputs":[{"name":"stdout","text":"+---+----------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+-------+\n|  #|            Name|Type 1|Type 2| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|BST|Med_Atk|\n+---+----------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+-------+\n|  1|       Bulbasaur| Grass|Poison| 45|    49|     49|     65|     65|   45|         1|    false|318|   NULL|\n|  2|         Ivysaur| Grass|Poison| 60|    62|     63|     80|     80|   60|         1|    false|405|   NULL|\n|  3|        Venusaur| Grass|Poison| 80|    82|     83|    100|    100|   80|         1|    false|525|   NULL|\n|  3|   Mega Venusaur| Grass|Poison| 80|   100|    123|    122|    120|   80|         1|    false|625|   NULL|\n|  4|      Charmander|  Fire|  NULL| 39|    52|     43|     60|     50|   65|         1|    false|309|   NULL|\n|  5|      Charmeleon|  Fire|  NULL| 58|    64|     58|     80|     65|   80|         1|    false|405|   NULL|\n|  6|       Charizard|  Fire|Flying| 78|    84|     78|    109|     85|  100|         1|    false|534|   NULL|\n|  6|Mega Charizard X|  Fire|Dragon| 78|   130|    111|    130|     85|  100|         1|    false|634|   NULL|\n|  6|Mega Charizard Y|  Fire|Flying| 78|   104|     78|    159|    115|  100|         1|    false|634|   NULL|\n|  7|        Squirtle| Water|  NULL| 44|    48|     65|     50|     64|   43|         1|    false|314|   NULL|\n|  8|       Wartortle| Water|  NULL| 59|    63|     80|     65|     80|   58|         1|    false|405|   NULL|\n|  9|       Blastoise| Water|  NULL| 79|    83|    100|     85|    105|   78|         1|    false|530|   NULL|\n|  9|  Mega Blastoise| Water|  NULL| 79|   103|    120|    135|    115|   78|         1|    false|630|   NULL|\n| 10|        Caterpie|   Bug|  NULL| 45|    30|     35|     20|     20|   45|         1|    false|195|   NULL|\n| 11|         Metapod|   Bug|  NULL| 50|    20|     55|     25|     25|   30|         1|    false|205|   NULL|\n| 12|      Butterfree|   Bug|Flying| 60|    45|     50|     90|     80|   70|         1|    false|395|   NULL|\n| 13|          Weedle|   Bug|Poison| 40|    35|     30|     20|     20|   50|         1|    false|195|   NULL|\n| 14|          Kakuna|   Bug|Poison| 45|    25|     50|     25|     25|   35|         1|    false|205|   NULL|\n| 15|        Beedrill|   Bug|Poison| 65|    90|     40|     45|     80|   75|         1|    false|395|   NULL|\n| 15|   Mega Beedrill|   Bug|Poison| 65|   150|     40|     15|     80|  145|         1|    false|495|   NULL|\n+---+----------------+------+------+---+------+-------+-------+-------+-----+----------+---------+---+-------+\nonly showing top 20 rows\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 8. ALS (Alternating Least Squares)","metadata":{}},{"cell_type":"markdown","source":"- [] **Start by creating a rating column using BST as the underpinning for the ratings: 300>BST>399: 3 , 400>BST>499: 4 ,500>BST>599: 5 ,600>BST>699: 6 ,700>BST>799: 7. Do this only for the Non-Legendary Pokémon, and leave it null for the Legendaries.**","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.recommendation import ALS\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.sql.functions import col, when, monotonically_increasing_id\n\n# Create synthetic rating based on BST\ndf_with_ratings = df.withColumn(\"rating\", \n                               when((df[\"BST\"] > 300) & (df[\"BST\"] <= 399), 3)\n                               .when((df[\"BST\"] > 400) & (df[\"BST\"] <= 499), 4)\n                               .when((df[\"BST\"] > 500) & (df[\"BST\"] <= 599), 5)\n                               .when((df[\"BST\"] > 600) & (df[\"BST\"] <= 699), 6)\n                               .when((df[\"BST\"] > 700) & (df[\"BST\"] <= 799), 7)\n                               .otherwise(None))  # None for Legendary Pokémon\n\n# Prepare user/item columns (using Pokemon IDs)\ndf_with_ids = df_with_ratings.withColumn(\"user\", monotonically_increasing_id()) \\\n                             .withColumn(\"item\", monotonically_increasing_id())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.192813Z","iopub.execute_input":"2025-03-29T23:49:05.193214Z","iopub.status.idle":"2025-03-29T23:49:05.247818Z","shell.execute_reply.started":"2025-03-29T23:49:05.193176Z","shell.execute_reply":"2025-03-29T23:49:05.246632Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"- [] **Now, implement an ALS model to predict what the rating will be for the Legendary Pokémon**","metadata":{}},{"cell_type":"code","source":"# Prepare the features for ALS model (using Pokémon stats)\nassembler = VectorAssembler(inputCols=[\"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"], outputCol=\"features\")\ndf_features = assembler.transform(df_with_ids)\n\n# Define ALS model\nals = ALS(maxIter=10, regParam=0.1, rank=10, userCol=\"user\", itemCol=\"item\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n\n# Train the ALS model\nmodel = als.fit(df_features)\n\n# Make predictions\npredictions = model.transform(df_features)\n\n# Show predictions for Pokémon with missing ratings (Legendary Pokémon)\npredictions.select(\"user\", \"item\", \"rating\", \"prediction\").filter(col(\"rating\").isNull()).show(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.248845Z","iopub.execute_input":"2025-03-29T23:49:05.249192Z","iopub.status.idle":"2025-03-29T23:49:05.827389Z","shell.execute_reply.started":"2025-03-29T23:49:05.249160Z","shell.execute_reply":"2025-03-29T23:49:05.825317Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-9d26bab4421e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prepare the features for ALS model (using Pokémon stats)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0massembler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorAssembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Attack\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Defense\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sp. Atk\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sp. Def\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Speed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_with_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define ALS model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Sp`.` Atk` cannot be resolved. Did you mean one of the following? [`#`, `Name`, `Type 1`, `Type 2`, `HP`, `Attack`, `Defense`, `Sp`.` Atk`, `Sp`.` Def`, `Speed`, `Generation`, `Legendary`, `BST`, `rating`, `user`, `item`]."],"ename":"AnalysisException","evalue":"[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Sp`.` Atk` cannot be resolved. Did you mean one of the following? [`#`, `Name`, `Type 1`, `Type 2`, `HP`, `Attack`, `Defense`, `Sp`.` Atk`, `Sp`.` Def`, `Speed`, `Generation`, `Legendary`, `BST`, `rating`, `user`, `item`].","output_type":"error"}],"execution_count":21},{"cell_type":"markdown","source":"## 9. K-Means Clustering","metadata":{}},{"cell_type":"markdown","source":"- [] **Find the best number of clusters for a K-Means analysis.**","metadata":{}},{"cell_type":"code","source":"cost = []\nfor k in range(2, 10):\n    kmeans = KMeans(featuresCol=\"features\", k=k, seed=42)\n    model = kmeans.fit(df)\n    cost.append(model.summary.trainingCost)\n\n\nplt.plot(range(2, 10), cost)\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"WSSSE\")\nplt.title(\"Elbow Method for Optimal K\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.829106Z","iopub.status.idle":"2025-03-29T23:49:05.830513Z","shell.execute_reply":"2025-03-29T23:49:05.830298Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- [] **Now, group the Pokémon into clusters.**","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.clustering import KMeans\n\n\nkmeans = KMeans(featuresCol=\"features\", k=5, seed=42)\nmodel = kmeans.fit(df)\n\n\nclustered_df = model.transform(df)\nclustered_df.select(\"features\", \"prediction\").show(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.831195Z","iopub.status.idle":"2025-03-29T23:49:05.831623Z","shell.execute_reply":"2025-03-29T23:49:05.831439Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10. PCA (Principal Component Analysis)","metadata":{}},{"cell_type":"markdown","source":"- [] **Check what the best features are in terms of predicting an outcome.**","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.feature import PCA\n\n# Apply PCA to reduce dimensions to 3\npca = PCA(k=3, inputCol=\"features\", outputCol=\"pca_features\")\npca_model = pca.fit(df)\npca_df = pca_model.transform(df)\n\npca_df.select(\"pca_features\").show(5, truncate=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.832864Z","iopub.status.idle":"2025-03-29T23:49:05.833352Z","shell.execute_reply":"2025-03-29T23:49:05.833098Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11. Linear Regression","metadata":{}},{"cell_type":"markdown","source":"- [] **What is the relationship between the Pokémon's stats (HP, Attack, Defense, Sp. Atk, Sp. Def, and Speed) and their Base Stat Total (BST)?**","metadata":{}},{"cell_type":"code","source":"df = df.withColumn(\"BST\", df.HP + df.Attack + df.Defense + df[\"Sp. Atk\"] + df[\"Sp. Def\"] + df.Speed)\n\n\nfeature_columns = [\"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]\nvector_assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\ndf_vector = vector_assembler.transform(df)\ndf_vector = df_vector.withColumnRenamed(\"BST\", \"label\")  \n\n\ntrain_data, test_data = df_vector.randomSplit([0.8, 0.2], seed=42)\n\n\nlr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\nlr_model = lr.fit(train_data)\n\n\npredictions = lr_model.transform(test_data)\npredictions.select(\"features\", \"label\", \"prediction\").show(5)\n\n\nrmse_evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\nr2_evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n\nrmse = rmse_evaluator.evaluate(predictions)\nr2 = r2_evaluator.evaluate(predictions)\n\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R² Score: {r2}\")\n\n# Step 9: Get model coefficients & intercept\nprint(\"Coefficients: \", lr_model.coefficients)\nprint(\"Intercept: \", lr_model.intercept)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.833993Z","iopub.status.idle":"2025-03-29T23:49:05.834679Z","shell.execute_reply":"2025-03-29T23:49:05.834445Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12. Random Forest","metadata":{}},{"cell_type":"markdown","source":"- [] **Start by doing feature importance to check which stats matter the most for predicting if a Pokémon is Legendary or not.**","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.stat import Correlation\nfrom pyspark.sql import functions as F\n\n# Assuming you have already loaded your dataframe into df\n# First, let's create the feature vector\nfeature_columns = ['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Generation']\n\n# To display the feature importance, we can extract the coefficients with their corresponding feature names\nfeature_importance = list(zip(feature_columns, coefficients))\nfeature_importance.sort(key=lambda x: abs(x[1]), reverse=True)\n\nprint(\"Feature Importance (sorted by absolute coefficient value):\")\nfor feature, coef in feature_importance:\n    print(f\"{feature}: {coef}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.836147Z","iopub.status.idle":"2025-03-29T23:49:05.837078Z","shell.execute_reply":"2025-03-29T23:49:05.836883Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- [] **Train a random forest model to predict whether a Pokémon is Legendary based on its stats**","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.classification import RandomForestClassifier\n\n\nrf = RandomForestClassifier(labelCol=\"LegendaryIndex\", featuresCol=\"features\", numTrees=100)\nrf_model = rf.fit(train)\n\n\nrf_predictions = rf_model.transform(test)\n\n\nrf_accuracy = evaluator.evaluate(rf_predictions)\nprint(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")\n\nrf_predictions.select(\"LegendaryIndex\", \"prediction\").show(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.838553Z","iopub.status.idle":"2025-03-29T23:49:05.839252Z","shell.execute_reply":"2025-03-29T23:49:05.839057Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 13. Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"- [] **Now apply the logistic regression model**","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.stat import Correlation\nfrom pyspark.sql import functions as F\n\n# Assuming you have already loaded your dataframe into df\n# First, let's create the feature vector\nfeature_columns = ['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Generation']\n\nassembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\ndf_features = assembler.transform(df)\n\n# Now, we'll define the Logistic Regression model\nlr = LogisticRegression(labelCol=\"Legendary\", featuresCol=\"features\")\n\n# Train the model\nlr_model = lr.fit(df_features)\n\n# Get the coefficients (feature importance)\ncoefficients = lr_model.coefficients\nintercept = lr_model.intercept\n\nprint(f\"Intercept: {intercept}\")\nprint(f\"Coefficients: {coefficients}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.840054Z","iopub.status.idle":"2025-03-29T23:49:05.841187Z","shell.execute_reply":"2025-03-29T23:49:05.840990Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 14. Gradient Boosting","metadata":{}},{"cell_type":"markdown","source":"- [] **What is the probability that a Pokémon is Legendary based on its features (such as HP, Attack, Defense, Sp. Atk, Sp. Def, Speed, etc.)?**","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Train a Gradient Boosting model\ngbt = GBTClassifier(labelCol=\"Legendary\", featuresCol=\"features\", maxIter=10)\n\n# Fit the model\ngbt_model = gbt.fit(df_features)\n\n# Make predictions\ngbt_predictions = gbt_model.transform(df_features)\n\n# Evaluate the model using ROC AUC\nevaluator = BinaryClassificationEvaluator(labelCol=\"Legendary\")\nroc_auc = evaluator.evaluate(gbt_predictions)\nprint(f\"ROC AUC: {roc_auc}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.842094Z","iopub.status.idle":"2025-03-29T23:49:05.842517Z","shell.execute_reply":"2025-03-29T23:49:05.842328Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 15. Neural Networks","metadata":{}},{"cell_type":"markdown","source":"- [] **Use a Neural Network model to predict the Legendary status of a Pokémon based on its stats**","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.classification import MultilayerPerceptronClassifier\n\n# Define layers: input layer (6 stats), hidden layers (5, 4), output (2: Legendary or not)\nlayers = [6, 5, 4, 2]\n\n# Initialize the neural network\nmlp = MultilayerPerceptronClassifier(labelCol=\"LegendaryIndex\", featuresCol=\"features\", layers=layers, maxIter=100)\n\n# Train the model\nmlp_model = mlp.fit(train)\n\n# Make predictions\nmlp_predictions = mlp_model.transform(test)\n\n# Evaluate accuracy\nmlp_accuracy = evaluator.evaluate(mlp_predictions)\nprint(f\"Neural Network Accuracy: {mlp_accuracy:.2f}\")\n\nmlp_predictions.select(\"LegendaryIndex\", \"prediction\").show(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.843974Z","iopub.status.idle":"2025-03-29T23:49:05.844686Z","shell.execute_reply":"2025-03-29T23:49:05.844386Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SQL Queries (Using the PySpark Library)","metadata":{}},{"cell_type":"markdown","source":"- [] **Rename the columns to be callable in SQL (substitute spaces an dots for underscores)**","metadata":{}},{"cell_type":"code","source":"df = df.withColumnRenamed(\"Sp. Atk\", \"Sp_Atk\")\ndf = df.withColumnRenamed(\"Sp. Def\", \"Sp_Def\")\n\n\ndf.show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.845833Z","iopub.status.idle":"2025-03-29T23:49:05.846335Z","shell.execute_reply":"2025-03-29T23:49:05.846102Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- [x] **Use a SQL statement to return a table with Pokémon that have a BST>600**","metadata":{}},{"cell_type":"code","source":"df.createOrReplaceTempView(\"BST_above_600\")\n\nresult = spark.sql(\"\"\"select *, (HP + Attack + Defense + Sp_Atk + Sp_Def + Speed) as BST\n    from pokemon_data\n    where (HP + Attack + Defense + Sp_Atk + Sp_Def + Speed) > 600\"\"\")\n\nresult.show()\n\n# We can also create a view\n\nspark.sql(\"\"\"\n    CREATE OR REPLACE TEMP VIEW BST AS\n    SELECT *, (HP + Attack + Defense + Sp_Atk + Sp_Def + Speed) AS BST\n    FROM pokemon_data\n\"\"\")\n\n# Now you can query the view\nresult_2 = spark.sql(\"SELECT * FROM BST WHERE BST > 600\")\n\n# Show the results\nresult_2.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.848144Z","iopub.status.idle":"2025-03-29T23:49:05.848804Z","shell.execute_reply":"2025-03-29T23:49:05.848586Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The important SQL queries for this project were already created and are in the MySQL files available in the \"Project 1: Pokémon\" folder, so I will not repeat them here.","metadata":{}},{"cell_type":"markdown","source":"- [x] **Don't forget to stop the spark session**","metadata":{}},{"cell_type":"code","source":"# spark.stop()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T23:49:05.849522Z","iopub.status.idle":"2025-03-29T23:49:05.850423Z","shell.execute_reply":"2025-03-29T23:49:05.850099Z"}},"outputs":[],"execution_count":null}]}